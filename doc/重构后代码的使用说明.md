# 重构后代码的使用说明 

### 主要特点 

* 模块化，方便实验不同的特征提取、生成数据样本的方法 
* 多线按批数据读取，以便处理大规模的数据集
* 提高代码可读性，以便协作 

### 目录结构 

- data: 和数据读取有关的模块
  - data_loader.py: 包含DataLoader类，接受一个数据文件列表，让程序可以调用next_batch函数直接按批次读取数据 
  - data_pair_loader.py: 包含DataPairLoader类，主要在训练时使用，接受两个数据文件列表，生成正负样本并成对地读取数据
  - 数据文件列表的具体格式请看另一篇文档 

- lib 和神经网络模型有关的模块 
  - fcn.py: 提供一些构造全连接层的函数 
  - gcn.py: 一个独立的图卷积网络模块，传入一个gcn_specs类的对象（可以理解为一个设计图纸），自动按要求构造图卷积网络 
  - mlnet.py: 这是一个metric learning网络的抽象基类，包含基础网络结构，loss，训练等的代码。它有两个抽象方法build_modal_1和build_modal_2，在实验不同的特征表示方法时，只需继承这个类，然后实现上面的两个抽象方法即可。
  - eval.py: 包含用于测量evaluation metric的函数，比如mean average precision

- models 包含那些继承了mlnet的类，用于实验各种不同的特征提取方法。
  - baseline0: 文字特征使用tf-idf, 图像特征使用vgg16
  - baseline1: 文字特征使用tf-idf, 图像特征使用vgg16+gcn
  - baseline2: 文字特征使用tf-idf+gcn, 图像特征使用vgg16

- modules: 外部引入的模块 
  - vgg16.py: 这是预训练的vgg16网络，可直接用来提取图像特征，使用时需要提供网络参数文件vgg16.npy 
  - graph.py: 和图计算有关的函数 

- main: 用于直接执行的脚本
  - train_baseline2_on_eng_wiki.py 在英文维基百科数据集上训练Baseline2
  - test_baseline2_on_eng_wiki.py 在英文维基百科数据集上测试Baseline2

  类，函数的具体使用方法，都已经在代码中充分注释。 

### 使用示例说明

假设我现在要试验一种新的特征提取方法，这种方法是用tf-idf作为文字特征，用vgg提取图像特征，并用gcn处理，假设这个方法称为Baseline1，那么步骤如下：

1. 在model.py中添加一个Baseline1类，继承MLNet类，然后实现里面的两个抽象方法build_modal_1和build_modal_2

```python
class Baseline1(MLNet):

    def __init__(self, vgg16_path, batch_size, desc_dims, out_dims, is_training=False):
        MLNet.__init__(self, batch_size, out_dims, is_training)
        self.desc_dims = desc_dims
        self.vgg16_path = vgg16_path

    def build_modal_1(self):
        M_text = 10055
        ph_text = tf.placeholder(tf.float32, [self.batch_size, M_text], 'input_text')
        text_descriptors, regularizers = self.fc(ph_text, self.desc_dims, activation_fn=None)
        self.regularizers += regularizers

        return ph_text, text_descriptors

    def build_modal_2(self):
        w, h, c = 224, 224, 3
        M_image = 49
        F_image = 512
        gcn_layers = 2

        ph_image = tf.placeholder(tf.float32, [self.batch_size, w, h, c], 'input_image')

        # vgg16 feature extraction
        self.vgg16 = Vgg16(self.vgg16_path)
        self.vgg16.build(ph_image)
        self.features = tf.reshape(self.vgg16.pool5, [-1, M_image, F_image])

        # laplacians
        A_image = np.ones([49, 49])
        A_image = sparse.csr_matrix(A_image).astype(np.float32)
        image_laplacians = [graph.laplacian(A_image, normalized=True) for _ in range(gcn_layers)]

        # specify GCN parameters
        specs = gcn_specs()
        specs.n_layers = gcn_layers
        specs.laplacians = image_laplacians
        specs.n_gconv_filters = [1, 1]
        specs.polynomial_orders = [3, 3]
        specs.pooling_sizes = [1, 1]
        specs.fc_dims = [1]
        specs.bias_type = 'per_filter'
        specs.pool_fn = tf.nn.max_pool
        specs.activation_fn = None
        specs.regularize = False

        # build GCN
        self.gcn = GCN(specs, is_training=self.is_training)
        gcn_out, regularizers = self.gcn.build(self.features, self.ph_dropout)
        self.regularizers += regularizers

        image_descriptors, regularizers = self.fc(gcn_out, self.desc_dims, activation_fn=None)
        self.regularizers += regularizers

        return ph_image, image_descriptors
```

2. 训练：训练的时需要初始化好一个DataPairLoader类的对象，然后调用MLNet提供的train函数

```python
# initialize data loader

text_dir = '/home/yzhq/data/eng-wiki/text'
image_dir = '/home/yzhq/data/eng-wiki/image'

text_train_path = '/home/yzhq/data/eng-wiki/text_train.txt'
image_train_path = '/home/yzhq/data/eng-wiki/image_train.txt'
text_val_path = '/home/yzhq/data/eng-wiki/text_val.txt'
image_val_path = '/home/yzhq/data/eng-wiki/image_val.txt'

n_classes = 10
batch_size = 128
n_loader_threads = 12

# 这两个函数是数据预处理函数，给DataLoader提供预处理函数，DataLoader就会把每一个数据用预处理函数处理一次。预处理函数是可选的，如果不提供预处理函数DataLoader会直接读取数据

def squeeze(path):
    arr = np.load(path)
    arr = np.squeeze(arr)
    return arr

def resize_and_to_bgr(path):
    img = cv2.imread(path)
    img = cv2.resize(img, (224, 224))
    if len(img.shape) == 3:
        # convert rgb to bgr
        img = img[..., [2, 1, 0]]
    else:
        # convert grayscale to bgr
        img = np.expand_dims(img, axis=2)
        img = np.repeat(img, 3, axis=2)
    return img

n_train = 4000
n_val = 1000

# 初始化好用于training和validation的两个DataLoader

train_loader = PosNegLoader(text_dir, image_dir,
                            text_train_path, image_train_path,
                            n_train, n_train,
                            batch_size=batch_size, n_classes=n_classes,
                            n_threads=n_loader_threads, shuffle=True,
                            process_fn_1=squeeze, process_fn_2=resize_and_to_bgr)

val_loader = PosNegLoader(text_dir, image_dir,
                            text_val_path, image_val_path,
                            n_val, n_val,
                            batch_size=batch_size, n_classes=n_classes,
                            n_threads=n_loader_threads, shuffle=True,
                            process_fn_1=squeeze, process_fn_2=resize_and_to_bgr)

# 建立神经网络结构

vgg16_path = '/home/yzhq/data/vgg16.npy'
desc_dims = 1024
out_dims = 1
net = Baseline1(vgg16_path, batch_size, desc_dims, out_dims, is_training=True)
net.build()

lamda = 0.35
mu = 0.8
regularization = 5e-3
net.build_loss(lamda, mu, regularization)

learning_rate = 1e-4
decay_rate = 0.95
decay_steps = train_loader.n_batches
net.build_train(learning_rate, decay_rate, decay_steps)

# 开始训练

n_epochs = 50
eval_freq = 400
dropout = 0.6
out_dir = os.path.join('..', 'out', 'baseline_1_on_eng_wiki')
log_dir = os.path.join(out_dir, 'log')
ckpt_dir = os.path.join(out_dir, 'checkpoints')
ckpt_name = "%d.model" % n_epochs
os.makedirs(out_dir, exist_ok=True)
os.makedirs(log_dir, exist_ok=True)
os.makedirs(ckpt_dir, exist_ok=True)

with tf.Session() as sess:
    net.build_summary(log_dir, sess)
    sess.run(tf.global_variables_initializer())
    net.train(n_epochs, dropout, eval_freq, sess, train_loader, val_loader)
    net.save(os.path.join(ckpt_dir, ckpt_name), sess)
```

3. 测试：目前可以用lib.eval里的mean_average_precision函数进行测试

```python
# 先初始化DataLoader

text_dir = '/home/yzhq/data/eng-wiki/text'
image_dir = '/home/yzhq/data/eng-wiki/image'

text_val_path = '/home/yzhq/data/eng-wiki/text_val.txt'
image_val_path = '/home/yzhq/data/eng-wiki/image_val.txt'

n_classes = 10
batch_size = 128
n_loader_threads = 12

def squeeze(path):
    arr = np.load(path)
    arr = np.squeeze(arr)
    return arr

def resize_and_to_bgr(path):
    img = cv2.imread(path)
    img = cv2.resize(img, (224, 224))
    if len(img.shape) == 3:
        # convert rgb to bgr
        img = img[..., [2, 1, 0]]
    else:
        # convert grayscale to bgr
        img = np.expand_dims(img, axis=2)
        img = np.repeat(img, 3, axis=2)
    return img

n_train = 4000
n_val = 1000

# 建立神经网络

vgg16_path = '/home/yzhq/data/vgg16.npy'
desc_dims = 1024
out_dims = 1
net = Baseline0(vgg16_path, batch_size, desc_dims, out_dims, is_training=False)
net.build()

# 开始测试

out_dir = os.path.join('..', 'out', 'baseline_0_on_eng_wiki')
log_dir = os.path.join(out_dir, 'log')
ckpt_dir = os.path.join(out_dir, 'checkpoints')
ckpt_name = "50.model"
ckpt_path = os.path.join(ckpt_dir, ckpt_name)

with tf.Session() as sess:
    net.restore(ckpt_path, sess)
    mAP1 = eval.mean_average_precision(net, sess, 1,
                                text_dir, image_dir,
                                text_val_path, image_val_path,
                                squeeze, resize_and_to_bgr,
                                batch_size, n_classes)
    mAP2 = eval.mean_average_precision(net, sess, 2,
                                text_dir, image_dir,
                                text_val_path, image_val_path,
                                squeeze, resize_and_to_bgr,
                                batch_size, n_classes)
    print("text to image: %.5f, image to text: %.5f" % (mAP1, mAP2))
```



